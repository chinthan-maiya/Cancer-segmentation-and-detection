{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Lambda \n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from keras.layers import Add \n",
    "import scipy.io as scio\n",
    "import numpy as np    \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "from scipy.misc import imsave\n",
    "from scipy import ndimage, misc\n",
    "from numpy import unravel_index\n",
    "from operator import sub\n",
    "from keras.layers import Reshape\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger,EarlyStopping,ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras import regularizers, optimizers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.load('total_images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.load('ground_truth_resized.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 256, 256, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_indices = np.random.choice(2000,1500,replace = False)\n",
    "x_train_images = []\n",
    "y_train_labels = [] \n",
    "for i in train_indices:\n",
    "    x_train_images.append(x[i])\n",
    "    y_train_labels.append(y[i])\n",
    "\n",
    "test_indices = [xy for xy in range(2000) if xy not in train_indices]\n",
    "x_test_images = []\n",
    "y_test_labels = []\n",
    "\n",
    "for i in test_indices:\n",
    "    x_test_images.append(x[i])\n",
    "    y_test_labels.append(y[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array(x_train_images)\n",
    "x_test = np.array(x_test_images)\n",
    "y_train = np.array(y_train_labels)\n",
    "y_test = np.array(y_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = 256\n",
    "cols = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_shape = 216*64\n",
    "weight_decay = 0.00011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 1792        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, None, 6 256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, None, None, 6 0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 1 73856       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, None, 1 512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, None, None, 1 0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 1 147584      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, None, 1 512         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_dil_1 (Conv2D)             (None, None, None, 1 147584      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 1 512         conv_dil_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv_dil_3 (Conv2D)             (None, None, None, 1 147584      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 1 512         conv_dil_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "skip_conv_1 (Conv2D)            (None, None, None, 1 147584      max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, None, 1 0           activation_35[0][0]              \n",
      "                                                                 skip_conv_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 1 147584      add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 1 512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "skip_conv_2 (Conv2D)            (None, None, None, 1 73856       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, None, 1 0           activation_36[0][0]              \n",
      "                                                                 skip_conv_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, None, None, 1 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 73792       up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 6 256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, None, 6 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 1 65          activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 1 0           conv2d_27[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 964,353\n",
      "Trainable params: 962,817\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defines the input tensor\n",
    "inputs = Input(shape=(None,None,3))\n",
    "\n",
    "L1 = Conv2D(64,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(inputs)\n",
    "L2 = BatchNormalization()(L1)\n",
    "L2 = Activation('relu')(L2)\n",
    "L3 = MaxPooling2D(pool_size=(2,2))(L2)\n",
    "L4 = Conv2D(128,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L3)\n",
    "L5 = BatchNormalization()(L4)\n",
    "L5 = Activation('relu')(L5)\n",
    "L6 = MaxPooling2D(pool_size=(2,2))(L5)\n",
    "L7 = Conv2D(128,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L6)\n",
    "L8 = BatchNormalization()(L7)\n",
    "L9 = Activation('relu')(L8)\n",
    "L10 = Conv2D(128,(3,3),dilation_rate= (2,2), padding = \"same\", activation='relu', name = \"conv_dil_1\")(L9)\n",
    "L11 = BatchNormalization()(L10)\n",
    "L12 = Activation('relu')(L11)\n",
    "L13 = Conv2D(128,(3,3),dilation_rate= (8,8), padding = \"same\", activation='relu', name = \"conv_dil_3\")(L12)\n",
    "L14 = BatchNormalization()(L13)\n",
    "L15 = Activation('relu')(L14)\n",
    "L16 = Conv2D(128,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay),\n",
    "             name=\"skip_conv_1\")(L6)\n",
    "L17 = Add()([L15,L16])\n",
    "L18 = UpSampling2D( size = (2,2)) (L17)\n",
    "\n",
    "L18 = Conv2D(128,(3,3), padding = \"same\", kernel_regularizer=regularizers.l2(weight_decay))(L17)\n",
    "L19 = BatchNormalization()(L18)\n",
    "L20 = Activation('relu')(L19)\n",
    "L21 = Conv2D(128,kernel_size=(3,3),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay),\n",
    "             name=\"skip_conv_2\")(L3)\n",
    "L21 = Add()([L20,L21])\n",
    "L22 = UpSampling2D(size = (2,2))(L21)\n",
    "L22 = Conv2D(64, (3,3), padding = \"same\", kernel_regularizer=regularizers.l2(weight_decay))(L22)\n",
    "L23 = BatchNormalization()(L22)\n",
    "L24 = Activation('relu')(L23)\n",
    "L25 = Conv2D(1,kernel_size=(1,1),padding = \"same\",kernel_regularizer=regularizers.l2(weight_decay))(L24)\n",
    "\n",
    "L26 = Activation('sigmoid')(L25)\n",
    "model = Model(inputs = inputs, outputs = L26)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(y_train.shape[0],256,256,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = y_test.reshape(y_test.shape[0],256,256,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_cf(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_cf_loss(y_true, y_pred):\n",
    "    return -dice_cf(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def customized_loss(y_true,y_pred):\n",
    "    return (1*K.binary_crossentropy(y_true, y_pred))+(0.5*dice_cf_loss(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimiser = optimizers.Adam(lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimiser,loss=dice_cf_loss,metrics=['accuracy',dice_cf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining Callback functions which will be called by model during runtime when specified condition satisfies\n",
    "lr_reducer = ReduceLROnPlateau(factor=0.5, cooldown=0, patience=6, min_lr=0.5e-6)\n",
    "csv_logger = CSVLogger('segmentation_lr_e2_bs4.csv')\n",
    "model_chekpoint = ModelCheckpoint(\"segmentation_lr_e2_bs4.hdf5\",monitor = 'val_loss',verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 500 samples\n",
      "Epoch 1/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.5413 - acc: 0.8522 - dice_coef: 0.6145Epoch 00000: val_loss improved from inf to -0.54429, saving model to segmentation_lr_e2_bs4.hdf5\n",
      "1500/1500 [==============================] - 496s - loss: -0.5415 - acc: 0.8524 - dice_coef: 0.6148 - val_loss: -0.5443 - val_acc: 0.8490 - val_dice_coef: 0.6322\n",
      "Epoch 2/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.6844 - acc: 0.9031 - dice_coef: 0.7299Epoch 00001: val_loss improved from -0.54429 to -0.68175, saving model to segmentation_lr_e2_bs4.hdf5\n",
      "1500/1500 [==============================] - 488s - loss: -0.6840 - acc: 0.9031 - dice_coef: 0.7295 - val_loss: -0.6818 - val_acc: 0.9088 - val_dice_coef: 0.7294\n",
      "Epoch 3/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.7345 - acc: 0.9196 - dice_coef: 0.7742Epoch 00002: val_loss did not improve\n",
      "1500/1500 [==============================] - 488s - loss: -0.7350 - acc: 0.9197 - dice_coef: 0.7747 - val_loss: -0.5421 - val_acc: 0.8939 - val_dice_coef: 0.5737\n",
      "Epoch 4/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.7578 - acc: 0.9262 - dice_coef: 0.7920Epoch 00003: val_loss improved from -0.68175 to -0.73656, saving model to segmentation_lr_e2_bs4.hdf5\n",
      "1500/1500 [==============================] - 488s - loss: -0.7573 - acc: 0.9262 - dice_coef: 0.7916 - val_loss: -0.7366 - val_acc: 0.9236 - val_dice_coef: 0.7709\n",
      "Epoch 5/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.7748 - acc: 0.9299 - dice_coef: 0.8026Epoch 00004: val_loss did not improve\n",
      "1500/1500 [==============================] - 488s - loss: -0.7752 - acc: 0.9301 - dice_coef: 0.8029 - val_loss: -0.5978 - val_acc: 0.8961 - val_dice_coef: 0.6275\n",
      "Epoch 6/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.7814 - acc: 0.9334 - dice_coef: 0.8090Epoch 00005: val_loss did not improve\n",
      "1500/1500 [==============================] - 488s - loss: -0.7816 - acc: 0.9335 - dice_coef: 0.8093 - val_loss: -0.7148 - val_acc: 0.9160 - val_dice_coef: 0.7441\n",
      "Epoch 7/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.8071 - acc: 0.9379 - dice_coef: 0.8254Epoch 00006: val_loss did not improve\n",
      "1500/1500 [==============================] - 488s - loss: -0.8072 - acc: 0.9379 - dice_coef: 0.8255 - val_loss: -0.6915 - val_acc: 0.8977 - val_dice_coef: 0.7183\n",
      "Epoch 8/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.8006 - acc: 0.9375 - dice_coef: 0.8239Epoch 00007: val_loss improved from -0.73656 to -0.75917, saving model to segmentation_lr_e2_bs4.hdf5\n",
      "1500/1500 [==============================] - 488s - loss: -0.8009 - acc: 0.9375 - dice_coef: 0.8241 - val_loss: -0.7592 - val_acc: 0.9303 - val_dice_coef: 0.7776\n",
      "Epoch 9/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.8194 - acc: 0.9407 - dice_coef: 0.8360Epoch 00008: val_loss improved from -0.75917 to -0.77240, saving model to segmentation_lr_e2_bs4.hdf5\n",
      "1500/1500 [==============================] - 488s - loss: -0.8191 - acc: 0.9407 - dice_coef: 0.8357 - val_loss: -0.7724 - val_acc: 0.9339 - val_dice_coef: 0.7882\n",
      "Epoch 10/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.8159 - acc: 0.9421 - dice_coef: 0.8349Epoch 00009: val_loss did not improve\n",
      "1500/1500 [==============================] - 488s - loss: -0.8160 - acc: 0.9422 - dice_coef: 0.8350 - val_loss: -0.7175 - val_acc: 0.9240 - val_dice_coef: 0.7353\n",
      "Epoch 11/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.8262 - acc: 0.9437 - dice_coef: 0.8434Epoch 00010: val_loss improved from -0.77240 to -0.77985, saving model to segmentation_lr_e2_bs4.hdf5\n",
      "1500/1500 [==============================] - 488s - loss: -0.8264 - acc: 0.9438 - dice_coef: 0.8436 - val_loss: -0.7798 - val_acc: 0.9366 - val_dice_coef: 0.7998\n",
      "Epoch 12/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.8316 - acc: 0.9461 - dice_coef: 0.8497Epoch 00011: val_loss improved from -0.77985 to -0.80280, saving model to segmentation_lr_e2_bs4.hdf5\n",
      "1500/1500 [==============================] - 488s - loss: -0.8318 - acc: 0.9461 - dice_coef: 0.8498 - val_loss: -0.8028 - val_acc: 0.9442 - val_dice_coef: 0.8188\n",
      "Epoch 13/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.8285 - acc: 0.9448 - dice_coef: 0.8432Epoch 00012: val_loss did not improve\n",
      "1500/1500 [==============================] - 487s - loss: -0.8287 - acc: 0.9449 - dice_coef: 0.8434 - val_loss: -0.6018 - val_acc: 0.8246 - val_dice_coef: 0.6193\n",
      "Epoch 14/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.8367 - acc: 0.9467 - dice_coef: 0.8498Epoch 00013: val_loss did not improve\n",
      "1500/1500 [==============================] - 488s - loss: -0.8361 - acc: 0.9463 - dice_coef: 0.8492 - val_loss: -0.4562 - val_acc: 0.8587 - val_dice_coef: 0.4666\n",
      "Epoch 15/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.8363 - acc: 0.9469 - dice_coef: 0.8493Epoch 00014: val_loss did not improve\n",
      "1500/1500 [==============================] - 488s - loss: -0.8365 - acc: 0.9470 - dice_coef: 0.8495 - val_loss: -0.7523 - val_acc: 0.9274 - val_dice_coef: 0.7648\n",
      "Epoch 16/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.8372 - acc: 0.9467 - dice_coef: 0.8517Epoch 00015: val_loss improved from -0.80280 to -0.80575, saving model to segmentation_lr_e2_bs4.hdf5\n",
      "1500/1500 [==============================] - 488s - loss: -0.8371 - acc: 0.9468 - dice_coef: 0.8517 - val_loss: -0.8057 - val_acc: 0.9415 - val_dice_coef: 0.8199\n",
      "Epoch 17/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.8478 - acc: 0.9493 - dice_coef: 0.8581Epoch 00016: val_loss did not improve\n",
      "1500/1500 [==============================] - 488s - loss: -0.8478 - acc: 0.9494 - dice_coef: 0.8582 - val_loss: -0.7311 - val_acc: 0.9210 - val_dice_coef: 0.7425\n",
      "Epoch 18/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.8475 - acc: 0.9505 - dice_coef: 0.8608Epoch 00017: val_loss did not improve\n",
      "1500/1500 [==============================] - 488s - loss: -0.8477 - acc: 0.9505 - dice_coef: 0.8609 - val_loss: -0.7941 - val_acc: 0.9399 - val_dice_coef: 0.8098\n",
      "Epoch 19/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.8484 - acc: 0.9502 - dice_coef: 0.8593Epoch 00018: val_loss did not improve\n",
      "1500/1500 [==============================] - 488s - loss: -0.8485 - acc: 0.9502 - dice_coef: 0.8594 - val_loss: -0.7827 - val_acc: 0.9346 - val_dice_coef: 0.7968\n",
      "Epoch 20/200\n",
      "1496/1500 [============================>.] - ETA: 1s - loss: -0.8511 - acc: 0.9509 - dice_coef: 0.8617Epoch 00019: val_loss improved from -0.80575 to -0.80813, saving model to segmentation_lr_e2_bs4.hdf5\n",
      "1500/1500 [==============================] - 488s - loss: -0.8510 - acc: 0.9508 - dice_coef: 0.8616 - val_loss: -0.8081 - val_acc: 0.9422 - val_dice_coef: 0.8181\n",
      "Epoch 21/200\n",
      "  52/1500 [>.............................] - ETA: 430s - loss: -0.8681 - acc: 0.9463 - dice_coef: 0.8786"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f50030cd67e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlr_reducer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsv_logger\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_chekpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1485\u001b[1;33m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1487\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[0;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1140\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1141\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 2073\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   2074\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2075\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=4,epochs=200,validation_data=(x_test, y_test),callbacks=[lr_reducer, csv_logger,model_chekpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('segmentation_lr_e2_bs4.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_image = x_test[1].reshape((1,256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(testing_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = prediction.reshape((256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = prediction > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f765402bc10>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJgAAAEACAYAAABPgL+7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDZiySgOmrNKAKas0YMoqDZiy6v8B+P9xyz3qwy4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7654082d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f761a261850>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAEACAYAAADcAZ91AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f76ae38aa10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(sample, cmap = \"gray\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(gt, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy=getTestSetAccuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy- 0.8602\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set accuracy-\",Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
